# -*- coding: utf-8 -*-
"""cnn_lstm_Updated_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a8XmG8jAV0DDPuO28bfEzlesHqTpzSmd
"""

import numpy as np
import pandas as pd

!pip install yfinance

# Commented out IPython magic to ensure Python compatibility.
import math
import seaborn as sns
import datetime as dt
from datetime import datetime    
sns.set_style("whitegrid")
from pandas.plotting import autocorrelation_plot
import matplotlib.pyplot as plt
# %matplotlib inline
plt.style.use("ggplot")
import yfinance as yf

# Download historical data for Apple Inc.
apple = yf.download("AAPL", start="2016-01-01", end="2023-03-17")

# Print the first few rows of the data
print(apple.head())

apple_df = pd.DataFrame(apple)
apple_df.to_csv("sp500_data.csv")

data = pd.read_csv("sp500_data.csv")
bool_series = pd.notnull(data["Adj Close"])
data[bool_series]

data.head()

data.info()

data.isnull().sum()

data.reset_index(drop=True, inplace=True)
data.fillna(data.mean(), inplace=True)
data.head()

data.plot(legend=True,subplots=True, figsize = (12, 6))
plt.show()



data.shape
data.size
data.describe(include='all').T
data.dtypes
data.nunique()
ma_day = [10,50,100]

for ma in ma_day:
    column_name = "MA for %s days" %(str(ma))
    data[column_name]=pd.DataFrame.rolling(data['Close'],ma).mean()

data['Daily Return'] = data['Close'].pct_change()
# plot the daily return percentage
data['Daily Return'].plot(figsize=(12,5),legend=True,linestyle=':',marker='o')
plt.show()

sns.displot(data['Daily Return'].dropna(),bins=100,color='green')
plt.show()

date=pd.DataFrame(data['Date'])
closing_df1 = pd.DataFrame(data['Close'])
close1  = closing_df1.rename(columns={"Close": "data_close"})
close2=pd.concat([date,close1],axis=1)
close2.head()

data.reset_index(drop=True, inplace=True)
data.fillna(data.mean(), inplace=True)
data.head()

data.nunique()

data.sort_index(axis=1,ascending=True)

cols_plot = ['Open', 'High', 'Low','Close','Volume','MA for 10 days','MA for 50 days','MA for 100 days','Daily Return']
axes = data[cols_plot].plot(marker='.', alpha=0.7, linestyle='None', figsize=(11, 9), subplots=True)
for ax in axes:
    ax.set_ylabel('Daily trade')

plt.plot(data['Close'], label="Close price")
plt.xlabel("Timestamp")
plt.ylabel("Closing price")
df = data
print(df)

data.isnull().sum()

cols_plot = ['Open', 'High', 'Low','Close']
axes = data[cols_plot].plot(marker='.', alpha=0.5, linestyle='None', figsize=(11, 9), subplots=True)
for ax in axes:
    ax.set_ylabel('Daily trade')

plt.plot(data['Close'], label="Close price")
plt.xlabel("Timestamp")
plt.ylabel("Closing price")
df = data
print(df)

df.describe().transpose()

from sklearn.model_selection import train_test_split

X = []
Y = []
window_size=100
for i in range(1 , len(df) - window_size -1 , 1):
    first = df.iloc[i,2]
    temp = []
    temp2 = []
    for j in range(window_size):
        temp.append((df.iloc[i + j, 2] - first) / first)
    temp2.append((df.iloc[i + window_size, 2] - first) / first)
    X.append(np.array(temp).reshape(100, 1))
    Y.append(np.array(temp2).reshape(1, 1))

X

from sklearn.model_selection import train_test_split

X = []
Y = []
window_size=100
for i in range(1 , len(df) - window_size -1 , 1):
    first = df.iloc[i,2]
    temp = []
    temp2 = []
    for j in range(window_size):
        temp.append((df.iloc[i + j, 2] - first) / first)
    temp2.append((df.iloc[i + window_size, 2] - first) / first)
    X.append(np.array(temp).reshape(100, 1))
    Y.append(np.array(temp2).reshape(1, 1))

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)

train_X = np.array(x_train)
test_X = np.array(x_test)
train_Y = np.array(y_train)
test_Y = np.array(y_test)

train_X = train_X.reshape(train_X.shape[0],1,100,1)
test_X = test_X.reshape(test_X.shape[0],1,100,1)

print(len(train_X))
print(len(test_X))

# For creating model and training
import tensorflow as tf
from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Bidirectional, TimeDistributed
from tensorflow.keras.layers import MaxPooling1D, Flatten
from tensorflow.keras.regularizers import L1, L2
from tensorflow.keras.metrics import Accuracy
from tensorflow.keras.metrics import RootMeanSquaredError

model = tf.keras.Sequential()

# Creating the Neural Network model here...
# CNN layers
model.add(TimeDistributed(Conv1D(64, kernel_size=3, activation='relu', input_shape=(None, 100, 1))))
model.add(TimeDistributed(MaxPooling1D(2)))
model.add(TimeDistributed(Conv1D(128, kernel_size=3, activation='relu')))
model.add(TimeDistributed(MaxPooling1D(2)))
model.add(TimeDistributed(Conv1D(64, kernel_size=3, activation='relu')))
model.add(TimeDistributed(MaxPooling1D(2)))
model.add(TimeDistributed(Flatten()))
# model.add(Dense(5, kernel_regularizer=L2(0.01)))

# LSTM layers
model.add(Bidirectional(LSTM(100, return_sequences=True)))
model.add(Dropout(0.5))
model.add(Bidirectional(LSTM(100, return_sequences=False)))
model.add(Dropout(0.5))

#Final layers
model.add(Dense(1, activation='linear'))
model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae', 'accuracy'])


history = model.fit(train_X, train_Y, validation_data=(test_X,test_Y), epochs=40,batch_size=40, verbose=1, shuffle =True)

test_loss, test_mse, test_mae = model.evaluate(test_X, test_Y)

print('Test accuracy:', test_accuracy)

from tensorflow.keras.utils import plot_model
plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.xlabel("epoch")
plt.ylabel("Loss")
plt.legend()

plt.plot(history.history['mse'], label='train mse')
plt.plot(history.history['val_mse'], label='val mse')
plt.xlabel("epoch")
plt.ylabel("Loss")
plt.legend()

plt.plot(history.history['mae'], label='train mae')
plt.plot(history.history['val_mae'], label='val mae')
plt.xlabel("epoch")
plt.ylabel("Loss")
plt.legend()

from tensorflow.keras.utils import plot_model
print(plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True))

model.evaluate(test_X, test_Y)

from sklearn.metrics import explained_variance_score, mean_poisson_deviance, mean_gamma_deviance
from sklearn.metrics import r2_score
from sklearn.metrics import max_error

# predict probabilities for test set
yhat_probs = model.predict(test_X, verbose=0)
# reduce to 1d array
yhat_probs = yhat_probs[:, 0]

var = explained_variance_score(test_Y.reshape(-1,1), yhat_probs)
print('Variance: %f' % var)

r2 = r2_score(test_Y.reshape(-1,1), yhat_probs)
print('R2 Score: %f' % var)

var2 = max_error(test_Y.reshape(-1,1), yhat_probs)
print('Max Error: %f' % var2)

# define the threshold for binary classification
threshold = 0.0

# predict probabilities for test set
yhat_probs = model.predict(test_X, verbose=0)
# reduce to 1d array
yhat_probs = yhat_probs[:, 0]

# classify predictions into binary classes using the threshold
yhat_classes = (yhat_probs > threshold).astype(int)
test_Y_classes = (test_Y > threshold).astype(int)

# calculate precision, recall, and accuracy
from sklearn.metrics import precision_score, recall_score, accuracy_score

precision = precision_score(test_Y_classes, yhat_classes)
recall = recall_score(test_Y_classes, yhat_classes)
accuracy = accuracy_score(test_Y_classes, yhat_classes)

print('Precision: %f' % precision)
print('Recall: %f' % recall)

predicted  = model.predict(test_X)
test_label = test_Y.reshape(-1,1)
predicted = np.array(predicted[:,0]).reshape(-1,1)
len_t = len(train_X)
for j in range(len_t , len_t + len(test_X)):
    temp = data.iloc[j,3]
    test_label[j - len_t] = test_label[j - len_t] * temp + temp
    predicted[j - len_t] = predicted[j - len_t] * temp + temp
plt.plot(predicted, color = 'green', label = 'Predicted  Stock Price')
plt.plot(test_label, color = 'red', label = 'Real Stock Price')
plt.title(' Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel(' Stock Price')
plt.legend()
plt.show()

"""Testing part:

In this part, the model is saved and loaded back again. Then, it's made to train again but with different data to check it's loss and prediction
"""

# First we need to save a model
model.save("model.h5")

# Load model
new_model = tf.keras.models.load_model("./model.h5")
new_model.summary()

# For data preprocessing and analysis part
#data2 = pd.read_csv('../input/price-volume-data-for-all-us-stocks-etfs/Stocks/aaoi.us.txt')
#data2 = pd.read_csv('../input/nifty50-stock-market-data/SBIN.csv')
#data2 = pd.read_csv('../input/stock-market-data/stock_market_data/nasdaq/csv/ACTG.csv')
data2 = pd.read_csv('TCS_stock_history.csv')
# Any CSV or TXT file can be added here....
data2.dropna(inplace=True)
data2.head()

data2.reset_index(drop=True, inplace=True)
data2.fillna(data.mean(), inplace=True)
data2.head()
df2 = data2.drop('Date', axis=1)

print(df2)

X = []
Y = []
window_size=100
for i in range(1 , len(df2) - window_size -1 , 1):
    first = df2.iloc[i,4]
    temp = []
    temp2 = []
    for j in range(window_size):
        temp.append((df2.iloc[i + j, 4] - first) / first)
    # for j in range(week):
    temp2.append((df2.iloc[i + window_size, 4] - first) / first)
    # X.append(np.array(stock.iloc[i:i+window_size,4]).reshape(50,1))
    # Y.append(np.array(stock.iloc[i+window_size,4]).reshape(1,1))
    # print(stock2.iloc[i:i+window_size,4])
    X.append(np.array(temp).reshape(100, 1))
    Y.append(np.array(temp2).reshape(1, 1))

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=False)

train_X = np.array(x_train)
test_X = np.array(x_test)
train_Y = np.array(y_train)
test_Y = np.array(y_test)

train_X = train_X.reshape(train_X.shape[0],1,100,1)
test_X = test_X.reshape(test_X.shape[0],1,100,1)

print(len(train_X))
print(len(test_X))



model.evaluate(test_X, test_Y)

predicted  = model.predict(test_X)
test_label = test_Y.reshape(-1,1)
predicted = np.array(predicted[:,0]).reshape(-1,1)
len_t = len(train_X)
for j in range(len_t , len_t + len(test_X)):
    temp = data2.iloc[j,3]
    test_label[j - len_t] = test_label[j - len_t] * temp + temp
    predicted[j - len_t] = predicted[j - len_t] * temp + temp
plt.plot(predicted, color = 'green', label = 'Predicted  Stock Price')
plt.plot(test_label, color = 'red', label = 'Real Stock Price')
plt.title(' Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel(' Stock Price')
plt.legend()
plt.show()

def predict_next_day(data, model):
    window_size = 100
    
    # Pad the data array with zeros if its length is less than window_size
    if len(data) < window_size:
        data = np.concatenate([np.zeros(window_size - len(data)), data])
    
    # Use the last window_size values to predict the next value
    last_window = data[-window_size:]
    
    # Reshape the data as required by the model
    last_window = np.array(last_window).reshape(1, 1, window_size, 1)

    # Make the prediction using the trained model
    prediction = model.predict(last_window)

    # Return the predicted value
    return prediction[0][0]

import numpy as np
import datetime

def predict_next_period(data, model, period='day', num_periods=1):
    # Determine the window size based on the period being predicted
    if period == 'day':
        window_size = 100
    elif period == 'week':
        window_size = 7 * 100
    elif period == 'month':
        window_size = 30 * 100
    
    # Pad the data array with zeros if its length is less than window_size
    if len(data) < window_size:
        data = np.concatenate([np.zeros(window_size - len(data)), data])
    
    # Use the last window_size values to predict the next value(s)
    last_window = data[-window_size:]
    
    # Reshape the data as required by the model
    if period == 'day':
        last_window = np.array(last_window).reshape(1, 1, window_size, 1)
    elif period == 'week':
        last_window = np.array(last_window).reshape(1, 1, window_size, 1)
        last_window = np.split(last_window, 7, axis=2)
        last_window = np.stack(last_window, axis=0)
    elif period == 'month':
        last_window = np.array(last_window).reshape(1, 1, window_size, 1)
        last_window = np.split(last_window, 30, axis=2)
        last_window = np.stack(last_window, axis=0)
    
    # Make the prediction using the trained model
    prediction = model.predict(last_window)

    # Return the predicted value(s)
    if period == 'day':
        return prediction[0][0]
    elif period == 'week':
        return prediction[0][0] * num_periods
    elif period == 'month':
        return prediction[0][0] * num_periods

test_Y_pred = model.predict(test_X)

test_Y_pred = test_Y_pred.reshape(test_Y_pred.shape[0], 1)
test_Y = test_Y.reshape(test_Y.shape[0], 1)

test_results = pd.DataFrame(np.concatenate((test_Y, test_Y_pred), axis=1), columns=['Actual', 'Predicted'])

test_results['Next Day'] = test_results['Actual'].shift(-1)
test_results['Next Week'] = test_results['Actual'].shift(-7)
test_results['Next Month'] = test_results['Actual'].shift(-30)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Calculate the log returns
data['Log Return'] = np.log(data['Adj Close'] / data['Adj Close'].shift(1)) * 100

# Calculate the rolling average of the log returns
data['Rolling Mean'] = data['Log Return'].rolling(window=30).mean()

# Calculate the rolling standard deviation of the log returns
data['Rolling Std'] = data['Log Return'].rolling(window=30).std()

# Calculate the upper and lower Bollinger Bands
data['Upper Band'] = data['Rolling Mean'] + 2 * data['Rolling Std']
data['Lower Band'] = data['Rolling Mean'] - 2 * data['Rolling Std']

# Calculate the next day prediction
next_day_prediction = data['Adj Close'].iloc[-1] * np.exp(data['Rolling Mean'].iloc[-1] / 100)

# Calculate the next week prediction
next_week_prediction = data['Adj Close'].iloc[-1] * np.exp(data['Rolling Mean'].iloc[-1] / 100 * 5)

# Calculate the next month prediction
next_month_prediction = data['Adj Close'].iloc[-1] * np.exp(data['Rolling Mean'].iloc[-1] / 100 * 22)

# Plot the adjusted close price, rolling mean, and Bollinger Bands
fig, ax = plt.subplots(figsize=(12, 6))
ax.plot(data.index, data['Adj Close'], label='Adjusted Close')
ax.plot(data.index, data['Rolling Mean'], label='Rolling Mean')
ax.plot(data.index, data['Upper Band'], label='Upper Band')
ax.plot(data.index, data['Lower Band'], label='Lower Band')

# Plot the next day, week, and month predictions
ax.axhline(y=next_day_prediction, color='g', linestyle='--', label='Next Day Prediction')
ax.axhline(y=next_week_prediction, color='r', linestyle='--', label='Next Week Prediction')
ax.axhline(y=next_month_prediction, color='m', linestyle='--', label='Next Month Prediction')

# Set the title and legend
ax.set_title('Stock Price with Bollinger Bands')
ax.legend()

# Show the plot
plt.show()

import matplotlib.pyplot as plt

# Define the data for each model
cnn_lstm_precision = 1.0
cnn_lstm_recall = 0.604811
lfm_precision = 0.8
lfm_recall = 0.5

# Create a bar chart
models = ['CNN-LSTM', 'LFM']
precisions = [cnn_lstm_precision, lfm_precision]
recalls = [cnn_lstm_recall, lfm_recall]
x = list(range(len(models)))
width = 0.35

fig, ax = plt.subplots()
rects1 = ax.bar([i - width/2 for i in x], precisions, width, label='Precision')
rects2 = ax.bar([i + width/2 for i in x], recalls, width, label='Recall')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Scores')
ax.set_title('Comparison of CNN-LSTM and LFM Models')
ax.set_xticks(x)
ax.set_xticklabels(models)
ax.legend()

# Add the precision and recall values to the bars
def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')
        
autolabel(rects1)
autolabel(rects2)

plt.show()

import matplotlib.pyplot as plt

# Define the data for each model
cnn_lstm_rmse = 0.0811
cnn_lstm_mae = 0.0221
cnn_lstm_mape = 0.034
lfm_rmse = 7.68
lfm_mae = 8.51
lfm_mape = 0.51

# Create a bar chart
models = ['CNN-LSTM', 'LFM']
rmse_values = [cnn_lstm_rmse, lfm_rmse]
mae_values = [cnn_lstm_mae, lfm_mae]
mape_values = [cnn_lstm_mape, lfm_mape]
x = list(range(len(models)))
width = 0.25

fig, ax = plt.subplots()
rects1 = ax.bar([i - width for i in x], rmse_values, width, label='RMSE')
rects2 = ax.bar(x, mae_values, width, label='MAE')
rects3 = ax.bar([i + width for i in x], mape_values, width, label='MAPE')

# Add some text for labels, title and custom x-axis tick labels, etc.
ax.set_ylabel('Error')
ax.set_title('Error Metrics for CNN-LSTM and LFM Models')
ax.set_xticks(x)
ax.set_xticklabels(models)
ax.legend()

# Add the values to the bars
def autolabel(rects):
    for rect in rects:
        height = rect.get_height()
        ax.annotate(f'{height:.2f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points vertical offset
                    textcoords="offset points",
                    ha='center', va='bottom')

autolabel(rects1)
autolabel(rects2)
autolabel(rects3)

plt.show()